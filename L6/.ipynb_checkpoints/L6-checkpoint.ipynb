{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rnd\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfChips = pd.read_csv('chips.csv')\n",
    "chipsTarget = dfChips['class']\n",
    "\n",
    "dfGeyser = pd.read_csv('geyser.csv')\n",
    "geyserTarget = dfGeyser['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XChips = dfChips[['x', 'y']]\n",
    "yChips = dfChips['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGeyser = dfGeyser[['x', 'y']]\n",
    "yGeyser = dfGeyser['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for val in yChips:\n",
    "    if(val == 'N'):\n",
    "        Y.append(-1)\n",
    "    else:\n",
    "        Y.append(1)\n",
    "        \n",
    "X = XChips.values.tolist()\n",
    "\n",
    "X, Y = shuffle(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitByBlock(X, Y, block, i):\n",
    "    x_train = X[0:(i*block)] + X[(i*block) + block:]\n",
    "    y_train = Y[0:(i*block)] + Y[(i*block) + block:]\n",
    "    x_test = X[(i*block): (i*block) + block]\n",
    "    y_test = Y[(i*block): (i*block) + block]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDots(x, y, bg_x, bg_y):\n",
    "    n = len(x)\n",
    "    m = len(bg_x)\n",
    "    \n",
    "    P_x1 = [x[i][0] for i in range(n) if y[i] >= 0]\n",
    "    P_x2 = [x[i][1] for i in range(n) if y[i] >= 0]\n",
    "            \n",
    "    N_x1 = [x[i][0] for i in range(n) if y[i] < 0]\n",
    "    N_x2 = [x[i][1] for i in range(n) if y[i] < 0]\n",
    "    \n",
    "    P_b1 = [bg_x[i][0] for i in range(m) if bg_y[i] >= 0]\n",
    "    P_b2 = [bg_x[i][1] for i in range(m) if bg_y[i] >= 0]\n",
    "            \n",
    "    N_b1 = [bg_x[i][0] for i in range(m) if bg_y[i] < 0]\n",
    "    N_b2 = [bg_x[i][1] for i in range(m) if bg_y[i] < 0]\n",
    "    \n",
    "    plt.scatter(P_x1, P_x2, marker='+', color='green')\n",
    "    plt.scatter(N_x1, N_x2, marker='_', color='red')\n",
    "    plt.scatter(P_b1, P_b2, marker='.', color='green', alpha = 0.2)\n",
    "    plt.scatter(N_b1, N_b2, marker='.', color='red', alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_Classifier:\n",
    "    \n",
    "    def fit(self, ds, weights=None):\n",
    "        if weights == None:\n",
    "            weights = [1.0 / len(ds) for e in range(len(ds))]\n",
    "        indices = [i for i in range(len(ds))]\n",
    "        \n",
    "        min_error = sys.maxsize\n",
    "        \n",
    "        best_f = -1\n",
    "        best_b = None\n",
    "        best_s = 0\n",
    "        \n",
    "        for f in range(len(ds[0]) - 1):\n",
    "            ds, indices = zip(*sorted(zip(ds, indices), key = lambda d:d[0][f]))\n",
    "            total_error = sum(weights)\n",
    "            cur_error = sum([weights[i] for i in range(len(ds)) if ds[i][-1] == -1])\n",
    "            \n",
    "            for i in range(len(ds) - 1):\n",
    "                index = indices[i]\n",
    "                \n",
    "                if ds[i][-1] == 1:\n",
    "                    cur_error += weights[index]\n",
    "                else:\n",
    "                    cur_error -= weights[index]\n",
    "                \n",
    "                if ds[i][f] == ds[i + 1][f]:\n",
    "                    continue\n",
    "                \n",
    "                if cur_error < min_error:\n",
    "                    min_error = cur_error\n",
    "                    best_f = f\n",
    "                    best_b = (ds[i][f] + ds[i + 1][f]) / 2\n",
    "                    best_s = 1\n",
    "                if (total_error - cur_error) < min_error:\n",
    "                    min_error = total_error - cur_error\n",
    "                    best_f = f\n",
    "                    best_b = (ds[i][f] + ds[i + 1][f]) / 2\n",
    "                    best_s = -1\n",
    "                    \n",
    "        self.f = best_f\n",
    "        self.b = best_b\n",
    "        self.s = best_s\n",
    "    def predict(self, d):\n",
    "        if d[self.f] < self.b:\n",
    "            return self.s\n",
    "        else:\n",
    "            return -1.0 * self.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "class Ada_Boost:\n",
    "    def fit(self, ds):\n",
    "        weights = [1.0 / len(ds) for e in range(len(ds))]\n",
    "        for epoch in range(EPOCHS):\n",
    "            simple = Simple_Classifier()\n",
    "            simple.fit(ds, weights)\n",
    "            error = 0\n",
    "            for i in range(len(ds)):\n",
    "                if simple.predict(ds[i][:-1]) != d[i][-1]:\n",
    "                    error += weights[i]\n",
    "#             error = sum([weights[i] for i in range(len(ds)) if simple.predict(ds[i][:-1]) != d[i][-1]])\n",
    "            if error >= 0.5:\n",
    "                break;\n",
    "            alpha = 0.5 * math.log((1 - error) / error)\n",
    "            \n",
    "            ws = 0.0\n",
    "            for i in range(len(ds)):\n",
    "                weights[i] *= math.exp(-1.0 * alpha * ds[i][-1] * simple.predict(ds[i][:-1]))\n",
    "                ws += weights[i]\n",
    "            weight = [w / ws for w in weights]\n",
    "            self.classifier = simple\n",
    "            if error == 0:\n",
    "                break\n",
    "    def predict(self, d):\n",
    "        return self.classifier.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chips = dfChips.to_numpy()\n",
    "for d in ds_chips:\n",
    "    d[-1] = -1 if d[-1] == 'N' else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05126699999999999, 0.6995600000000001, 1],\n",
       "       [-0.09274199999999999, 0.68494, 1],\n",
       "       [-0.21370999999999998, 0.69225, 1],\n",
       "       [-0.375, 0.5021899999999999, 1],\n",
       "       [-0.51325, 0.46563999999999994, 1],\n",
       "       [-0.52477, 0.2098, 1],\n",
       "       [-0.39804, 0.034357, 1],\n",
       "       [-0.30588000000000004, -0.19225, 1],\n",
       "       [0.016705, -0.40424, 1],\n",
       "       [0.13191, -0.51389, 1],\n",
       "       [0.38537, -0.56506, 1],\n",
       "       [0.5293800000000001, -0.5212, 1],\n",
       "       [0.6388199999999999, -0.24341999999999997, 1],\n",
       "       [0.73675, -0.18494000000000002, 1],\n",
       "       [0.54666, 0.48757, 1],\n",
       "       [0.322, 0.5826, 1],\n",
       "       [0.16647, 0.53874, 1],\n",
       "       [-0.046659, 0.81652, 1],\n",
       "       [-0.17339000000000002, 0.6995600000000001, 1],\n",
       "       [-0.47868999999999995, 0.63377, 1],\n",
       "       [-0.60541, 0.59722, 1],\n",
       "       [-0.62846, 0.33405999999999997, 1],\n",
       "       [-0.5938899999999999, 0.005117, 1],\n",
       "       [-0.42108, -0.27266, 1],\n",
       "       [-0.11578, -0.39693, 1],\n",
       "       [0.20104, -0.6016100000000001, 1],\n",
       "       [0.46601000000000004, -0.53582, 1],\n",
       "       [0.6733899999999999, -0.53582, 1],\n",
       "       [-0.13882, 0.54605, 1],\n",
       "       [-0.29435, 0.7799699999999999, 1],\n",
       "       [-0.26555, 0.96272, 1],\n",
       "       [-0.16187, 0.8019, 1],\n",
       "       [-0.17339000000000002, 0.6483899999999999, 1],\n",
       "       [-0.28283, 0.47295, 1],\n",
       "       [-0.36348, 0.31213, 1],\n",
       "       [-0.30012, 0.027047, 1],\n",
       "       [-0.23675, -0.21418, 1],\n",
       "       [-0.06394, -0.18494000000000002, 1],\n",
       "       [0.062788, -0.16301, 1],\n",
       "       [0.22984000000000002, -0.41155, 1],\n",
       "       [0.2932, -0.2288, 1],\n",
       "       [0.48328999999999994, -0.18494000000000002, 1],\n",
       "       [0.64459, -0.14107999999999998, 1],\n",
       "       [0.46025, 0.012426999999999999, 1],\n",
       "       [0.6273, 0.15863, 1],\n",
       "       [0.5754600000000001, 0.26827, 1],\n",
       "       [0.72523, 0.44371000000000005, 1],\n",
       "       [0.22408000000000003, 0.52412, 1],\n",
       "       [0.44297, 0.67032, 1],\n",
       "       [0.322, 0.69225, 1],\n",
       "       [0.13767000000000001, 0.57529, 1],\n",
       "       [-0.0063364, 0.39985, 1],\n",
       "       [-0.09274199999999999, 0.5533600000000001, 1],\n",
       "       [-0.20795, 0.35599000000000003, 1],\n",
       "       [-0.20795, 0.17325, 1],\n",
       "       [-0.43836, 0.21711, 1],\n",
       "       [-0.21946999999999997, -0.016812999999999998, 1],\n",
       "       [-0.13882, -0.27266, 1],\n",
       "       [0.18375999999999998, 0.93348, -1],\n",
       "       [0.22408000000000003, 0.7799699999999999, -1],\n",
       "       [0.29896, 0.61915, -1],\n",
       "       [0.50634, 0.7580399999999999, -1],\n",
       "       [0.61578, 0.7288, -1],\n",
       "       [0.60426, 0.59722, -1],\n",
       "       [0.76555, 0.5021899999999999, -1],\n",
       "       [0.92684, 0.3633, -1],\n",
       "       [0.82316, 0.27558, -1],\n",
       "       [0.96141, 0.085526, -1],\n",
       "       [0.9383600000000001, 0.012426999999999999, -1],\n",
       "       [0.8634799999999999, -0.082602, -1],\n",
       "       [0.89804, -0.20686999999999997, -1],\n",
       "       [0.85196, -0.36769, -1],\n",
       "       [0.8289200000000001, -0.5212, -1],\n",
       "       [0.79435, -0.55775, -1],\n",
       "       [0.5927399999999999, -0.7405, -1],\n",
       "       [0.51786, -0.5943, -1],\n",
       "       [0.46601000000000004, -0.41886, -1],\n",
       "       [0.35081, -0.57968, -1],\n",
       "       [0.28744000000000003, -0.76974, -1],\n",
       "       [0.085829, -0.75512, -1],\n",
       "       [0.14919000000000002, -0.57968, -1],\n",
       "       [-0.13305999999999998, -0.4481, -1],\n",
       "       [-0.40956, -0.41155, -1],\n",
       "       [-0.39228, -0.25804, -1],\n",
       "       [-0.74366, -0.25804, -1],\n",
       "       [-0.69758, 0.041667, -1],\n",
       "       [-0.7551800000000001, 0.2902, -1],\n",
       "       [-0.69758, 0.68494, -1],\n",
       "       [-0.4038, 0.70687, -1],\n",
       "       [-0.38076, 0.91886, -1],\n",
       "       [-0.50749, 0.9042399999999999, -1],\n",
       "       [-0.54781, 0.70687, -1],\n",
       "       [0.10311, 0.7799699999999999, -1],\n",
       "       [0.057027999999999995, 0.91886, -1],\n",
       "       [-0.10425999999999999, 0.9919600000000001, -1],\n",
       "       [-0.081221, 1.1089, -1],\n",
       "       [0.28744000000000003, 1.087, -1],\n",
       "       [0.39689, 0.82383, -1],\n",
       "       [0.6388199999999999, 0.8896200000000001, -1],\n",
       "       [0.82316, 0.66301, -1],\n",
       "       [0.6733899999999999, 0.64108, -1],\n",
       "       [1.0709, 0.10015, -1],\n",
       "       [-0.046659, -0.57968, -1],\n",
       "       [-0.23675, -0.6381600000000001, -1],\n",
       "       [-0.15035, -0.36769, -1],\n",
       "       [-0.49021000000000003, -0.3019, -1],\n",
       "       [-0.46717, -0.13377, -1],\n",
       "       [-0.28859, -0.060673000000000005, -1],\n",
       "       [-0.6111800000000001, -0.067982, -1],\n",
       "       [-0.6630199999999999, -0.21418, -1],\n",
       "       [-0.59965, -0.41886, -1],\n",
       "       [-0.72638, -0.082602, -1],\n",
       "       [-0.8300700000000001, 0.31213, -1],\n",
       "       [-0.7206199999999999, 0.53874, -1],\n",
       "       [-0.5938899999999999, 0.49488000000000004, -1],\n",
       "       [-0.48445, 0.9992700000000001, -1],\n",
       "       [-0.0063364, 0.9992700000000001, -1],\n",
       "       [0.63265, -0.030612, -1]], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booster = Ada_Boost()\n",
    "ds_chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-fe9f5fbce840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_chips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-7f95e710f707>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, ds)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msimple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimple_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msimple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msimple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-7f95e710f707>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0msimple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimple_Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msimple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msimple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "booster.fit(ds_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
